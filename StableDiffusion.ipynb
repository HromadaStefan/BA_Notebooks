{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7da835b-bda1-4ca5-9590-75c81a6b1cde",
   "metadata": {},
   "source": [
    "# Generieren der Bilder:\n",
    "\n",
    "Beim generieren der Bilder wurde sich am Angfang auf Bilder von Autos beschränkt, da eine bestimmte \"Kategorie\" an Bilder den Erkennungsprozess erheblich erleichtern.\n",
    "\n",
    "Um ein möglichst ausbalanciertes Dataset an KI-generierten Bilder zu erlangen, werden verschiedene prompts genutzt: \\\n",
    "    1) \"familycar\" \\\n",
    "    2) \"sportscar\" \\\n",
    "    3) \"old car\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14fa8b8-32ac-45dd-8df3-fb31193c8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "device = \"cuda\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "def generateImages(amountOfEachPrompt, prompt, variations, targetdir):\n",
    "    for i in range (amountOfEachPrompt):\n",
    "        for i2 in variations:\n",
    "            newprompt = i2 + prompt\n",
    "            image = pipe(i2 + prompt).images[0]\n",
    "            image.save(targetdir + newprompt.replace(' ', '_') + str(i) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad9008-366c-4faa-88a1-2d92a3c5b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"car\"\n",
    "variations = [\"family\", \"sports\", \"old \"]\n",
    "amountOfEachPrompt = 20\n",
    "\n",
    "targetDir = \"./\"\n",
    "\n",
    "generateImages(amountOfEachPrompt, prompt, variations, targetDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcfd4f5-9bee-48b6-9ed9-e7cb08a4734d",
   "metadata": {},
   "source": [
    "## Fazit der ersten Generierung:\n",
    "\n",
    " + Resulate waren gut. Bilder konnten überraschend gut klassifiziert werden.\n",
    " \n",
    " - Bilder mit dem prompt familycar beinhalteten oft Menschen, welche deutlich erkennbar generiert sind. Im Dataset der realen Bilder befinden sich deutlich weniger menschen auf den Fotos.\n",
    " - Stable Diffusion 1.4 ist etwas veraltet --> neuere Modelle, welche realistischere Bilder erzeugen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8084daa8-a3d0-4c94-8000-ed8dcdf06e6a",
   "metadata": {},
   "source": [
    "## Reale Bilder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18901898-81d4-4d52-8514-8a12b681dc41",
   "metadata": {},
   "source": [
    "Link: https://www.kaggle.com/datasets/jessicali9530/stanford-cars-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da0e87f-a05d-40f1-8d8e-ab5fcc55b769",
   "metadata": {},
   "source": [
    "In dem Dataset wird angegeben, dass die Bilder labels beinhalten: Baujahr, Modellbezeichnung, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b512fa-1939-4866-b08c-f0d2536e6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "# Pfad zur .mat Datei\n",
    "mat_file_path = './images/car/cars_annos.mat'\n",
    "\n",
    "# Laden der .mat Datei\n",
    "mat_contents = loadmat(mat_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48541e19-1c09-4f2d-a44a-7dcce627cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels passen aus meiner Sicht nicht zu den Bildern --> Deshalb eigenes Feature-Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2468ea03-62f2-483a-b216-4cbcb2caf2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "# Laden der .mat Datei\n",
    "mat_file = './images/car/cars_annos.mat'\n",
    "mat_contents = loadmat(mat_file)\n",
    "\n",
    "# Extrahieren der Annotations und Class Names\n",
    "annotations = mat_contents['annotations']\n",
    "class_names = mat_contents['class_names'][0]\n",
    "\n",
    "# Erstellen eines Dictionaries, das die Bildpfade auf ihre Labels abbildet\n",
    "image_label_map = {}\n",
    "\n",
    "for annotation in annotations[0]:\n",
    "    image_path = annotation[0][0].split('/')[1]  # Pfad zum Bild\n",
    "    class_index = annotation[5][0][0] - 1  # Index des Labels (angepasst für 0-basierte Indizierung)\n",
    "    label = class_names[class_index][0]  # Das tatsächliche Label\n",
    "    image_label_map[image_path] = label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
